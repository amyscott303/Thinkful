{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/amyscott/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /anaconda3/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "    /anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import sklearn as ensemble\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/bin/python\n",
      "3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, stopwords\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "\n",
    "poem = gutenberg.raw('blake-poems.txt')\n",
    "thursday= gutenberg.raw('chesterton-thursday.txt')\n",
    "bryant= gutenberg.raw('bryant-stories.txt')\n",
    "burgess= gutenberg.raw('burgess-busterbrown.txt')\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "brown= gutenberg.raw('chesterton-brown.txt')\n",
    "paradise= gutenberg.raw('milton-paradise.txt')\n",
    "whitman= gutenberg.raw('whitman-leaves.txt')\n",
    "sense= gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "\n",
    "poem = re.sub(r'Chapter \\d+', '', poem)\n",
    "thursday = re.sub(r'CHAPTER .*', '', thursday)\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'Chapter \\d+', '', alice)\n",
    "bryant = re.sub(r'Chapter \\d+', '', bryant)\n",
    "brown = re.sub(r'Chapter \\d+', '', brown)\n",
    "paradise = re.sub(r'Chapter \\d+', '', paradise)\n",
    "whitman = re.sub(r'Chapter \\d+', '', whitman)\n",
    "sense = re.sub(r'Chapter \\d+', '', sense)\n",
    "burgess = re.sub(r'Chapter \\d+', '', burgess)\n",
    "\n",
    "    \n",
    "poem = text_cleaner(poem[:int(len(poem)/30)])\n",
    "thursday = text_cleaner(thursday[:int(len(thursday)/30)])\n",
    "alice = text_cleaner(alice[:int(len(alice)/30)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/30)])\n",
    "bryant = text_cleaner(bryant[:int(len(bryant)/30)])\n",
    "brown = text_cleaner(brown[:int(len(brown)/30)])\n",
    "paradise = text_cleaner(paradise[:int(len(paradise)/30)])\n",
    "whitman = text_cleaner(whitman[:int(len(whitman)/30)])\n",
    "sense = text_cleaner(sense[:int(len(sense)/30)])\n",
    "burgess = text_cleaner(burgess[:int(len(burgess)/30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "nlp.max_length\n",
    "\n",
    "poem_doc = nlp(poem)\n",
    "thursday_doc = nlp(thursday)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "alice_doc = nlp(alice)\n",
    "bryant_doc = nlp(bryant)\n",
    "brown_doc = nlp(brown)\n",
    "paradise_doc = nlp(paradise)\n",
    "whitman_doc= nlp(whitman)\n",
    "sense_doc = nlp(sense)\n",
    "burgess_doc = nlp(burgess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CHAPTER, I.)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Down, the, Rabbit, -, Hole, Alice, was, begin...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0                                      (CHAPTER, I.)  Carroll\n",
       "1  (Down, the, Rabbit, -, Hole, Alice, was, begin...  Carroll\n",
       "2  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "3  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem_sents = [[sent, \"Blake\"] for sent in poem_doc.sents]\n",
    "thursday_sents = [[sent, \"Chesterton\"] for sent in thursday_doc.sents]\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "bryant_sents = [[sent, \"Bryant\"] for sent in bryant_doc.sents]\n",
    "brown_sents = [[sent, \"Chesterton-Brown\"] for sent in brown_doc.sents]\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "whitman_sents = [[sent, \"Whitman\"] for sent in whitman_doc.sents]\n",
    "sense_sents = [[sent, \"Austen-Sense\"] for sent in sense_doc.sents]\n",
    "burgess_sents = [[sent, \"Burgess\"] for sent in burgess_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents + poem_sents + thursday_sents + bryant_sents + brown_sents \n",
    "                        + paradise_sents +  whitman_sents + sense_sents + burgess_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "poemwords = bag_of_words(poem_doc)\n",
    "thursdaywords = bag_of_words(thursday_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "bryantwords = bag_of_words(bryant_doc)\n",
    "brownwords = bag_of_words(brown_doc)\n",
    "brownwords = bag_of_words(paradise_doc)\n",
    "whitmanwords= bag_of_words(whitman_doc)\n",
    "sensewords = bag_of_words(sense_doc)\n",
    "burgesswords = bag_of_words(burgess_doc)\n",
    "\n",
    "\n",
    "\n",
    "common_words = set(poemwords + thursdaywords + persuasionwords + alicewords + bryantwords  + \n",
    "                   brownwords + brownwords + whitmanwords + sensewords + burgesswords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intellectual</th>\n",
       "      <th>draw</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>precisely</th>\n",
       "      <th>cheerful</th>\n",
       "      <th>haply</th>\n",
       "      <th>lay</th>\n",
       "      <th>deserve</th>\n",
       "      <th>stately</th>\n",
       "      <th>following</th>\n",
       "      <th>...</th>\n",
       "      <th>penal</th>\n",
       "      <th>regular</th>\n",
       "      <th>strange</th>\n",
       "      <th>unbounded</th>\n",
       "      <th>interesting</th>\n",
       "      <th>proof</th>\n",
       "      <th>outshine</th>\n",
       "      <th>sister</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(CHAPTER, I.)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(Down, the, Rabbit, -, Hole, Alice, was, begin...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  intellectual draw aggregate precisely cheerful haply lay deserve stately  \\\n",
       "0            0    0         0         0        0     0   0       0       0   \n",
       "1            0    0         0         0        0     0   0       0       0   \n",
       "2            0    0         0         0        0     0   0       0       0   \n",
       "3            0    0         0         0        0     0   0       0       0   \n",
       "4            0    0         0         0        0     0   0       0       0   \n",
       "\n",
       "  following  ... penal regular strange unbounded interesting proof outshine  \\\n",
       "0         0  ...     0       0       0         0           0     0        0   \n",
       "1         0  ...     0       0       0         0           0     0        0   \n",
       "2         0  ...     0       0       0         0           0     0        0   \n",
       "3         0  ...     0       0       0         0           0     0        0   \n",
       "4         0  ...     0       0       0         0           0     0        0   \n",
       "\n",
       "  sister                                      text_sentence text_source  \n",
       "0      0                                      (CHAPTER, I.)     Carroll  \n",
       "1      2  (Down, the, Rabbit, -, Hole, Alice, was, begin...     Carroll  \n",
       "2      0  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "3      0  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "4      0                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 3050 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    intellectual draw aggregate precisely cheerful haply lay deserve stately  \\\n",
      "0              0    0         0         0        0     0   0       0       0   \n",
      "1              0    0         0         0        0     0   0       0       0   \n",
      "2              0    0         0         0        0     0   0       0       0   \n",
      "3              0    0         0         0        0     0   0       0       0   \n",
      "4              0    0         0         0        0     0   0       0       0   \n",
      "5              0    0         0         0        0     0   0       0       0   \n",
      "6              0    0         0         0        0     0   0       0       0   \n",
      "7              0    0         0         0        0     0   0       0       0   \n",
      "8              0    0         0         0        0     0   0       0       0   \n",
      "9              0    0         0         0        0     0   0       0       0   \n",
      "10             0    0         0         0        0     0   0       0       0   \n",
      "11             0    0         0         0        0     0   0       0       0   \n",
      "12             0    0         0         0        0     0   0       0       0   \n",
      "13             0    0         0         0        0     0   0       0       0   \n",
      "14             0    0         0         0        0     0   0       0       0   \n",
      "15             0    0         0         0        0     0   0       0       0   \n",
      "16             0    0         0         0        0     0   0       0       0   \n",
      "17             0    0         0         0        0     0   0       0       0   \n",
      "18             0    0         0         0        0     0   0       0       0   \n",
      "19             0    0         0         0        0     0   0       0       0   \n",
      "20             0    0         0         0        0     0   0       0       0   \n",
      "21             0    0         0         0        0     0   0       0       0   \n",
      "22             0    0         0         0        0     0   0       0       0   \n",
      "23             0    0         0         0        0     0   0       0       0   \n",
      "24             0    0         0         0        0     0   0       0       0   \n",
      "25             0    0         0         0        0     0   0       0       0   \n",
      "26             0    0         0         0        0     0   0       0       0   \n",
      "27             0    0         0         0        0     0   0       0       0   \n",
      "28             0    0         0         0        0     0   0       0       0   \n",
      "29             0    0         0         0        0     0   0       0       0   \n",
      "..           ...  ...       ...       ...      ...   ...  ..     ...     ...   \n",
      "929            0    0         0         0        0     0   0       0       0   \n",
      "930            0    0         0         0        0     0   0       0       0   \n",
      "931            0    0         0         0        0     0   0       0       0   \n",
      "932            0    0         0         0        0     0   0       0       0   \n",
      "933            0    0         0         0        0     0   0       0       0   \n",
      "934            0    0         0         0        0     0   0       0       0   \n",
      "935            0    0         0         0        0     0   0       0       0   \n",
      "936            0    0         0         0        0     0   0       0       0   \n",
      "937            0    0         0         0        0     0   0       0       0   \n",
      "938            0    0         0         0        0     0   0       0       0   \n",
      "939            0    0         0         0        0     0   0       0       0   \n",
      "940            0    0         0         0        0     0   0       0       0   \n",
      "941            0    0         0         0        0     0   0       0       0   \n",
      "942            0    0         0         0        0     0   0       0       0   \n",
      "943            0    0         0         0        0     0   0       0       0   \n",
      "944            0    0         0         0        0     0   0       0       0   \n",
      "945            0    0         0         0        0     0   0       0       0   \n",
      "946            0    1         0         0        0     0   0       0       0   \n",
      "947            0    0         0         0        0     0   0       0       0   \n",
      "948            0    0         0         0        0     0   0       0       0   \n",
      "949            0    0         0         0        0     0   0       0       0   \n",
      "950            0    0         0         0        0     0   0       0       0   \n",
      "951            0    0         0         0        0     0   0       0       0   \n",
      "952            0    0         0         0        0     0   0       0       0   \n",
      "953            0    0         0         0        0     0   0       0       0   \n",
      "954            0    0         0         0        0     0   0       0       0   \n",
      "955            0    0         0         0        0     0   0       0       0   \n",
      "956            0    0         0         0        0     0   0       0       0   \n",
      "957            0    0         0         0        0     0   0       0       0   \n",
      "958            0    0         0         0        0     0   0       0       0   \n",
      "\n",
      "    following  ... baronetcy dreary penal regular strange unbounded  \\\n",
      "0           0  ...         0      0     0       0       0         0   \n",
      "1           0  ...         0      0     0       0       0         0   \n",
      "2           0  ...         0      0     0       0       0         0   \n",
      "3           0  ...         0      0     0       0       0         0   \n",
      "4           0  ...         0      0     0       0       0         0   \n",
      "5           0  ...         0      0     0       0       0         0   \n",
      "6           0  ...         0      0     0       0       0         0   \n",
      "7           0  ...         0      0     0       0       0         0   \n",
      "8           0  ...         0      0     0       0       0         0   \n",
      "9           0  ...         0      0     0       0       0         0   \n",
      "10          0  ...         0      0     0       0       0         0   \n",
      "11          0  ...         0      0     0       0       0         0   \n",
      "12          0  ...         0      0     0       0       0         0   \n",
      "13          0  ...         0      0     0       0       0         0   \n",
      "14          0  ...         0      0     0       0       0         0   \n",
      "15          0  ...         0      0     0       0       0         0   \n",
      "16          0  ...         0      0     0       0       0         0   \n",
      "17          0  ...         0      0     0       0       0         0   \n",
      "18          0  ...         0      0     0       0       0         0   \n",
      "19          0  ...         0      0     0       0       0         0   \n",
      "20          0  ...         0      0     0       0       0         0   \n",
      "21          0  ...         0      0     0       0       0         0   \n",
      "22          0  ...         0      0     0       0       0         0   \n",
      "23          0  ...         0      0     0       0       0         0   \n",
      "24          0  ...         0      0     0       0       0         0   \n",
      "25          0  ...         0      0     0       0       0         0   \n",
      "26          0  ...         0      0     0       0       0         0   \n",
      "27          0  ...         0      0     0       0       0         0   \n",
      "28          0  ...         0      0     0       0       0         0   \n",
      "29          0  ...         0      0     0       0       0         0   \n",
      "..        ...  ...       ...    ...   ...     ...     ...       ...   \n",
      "929         0  ...         0      0     0       0       0         0   \n",
      "930         0  ...         0      0     0       0       0         0   \n",
      "931         0  ...         0      0     0       0       0         0   \n",
      "932         0  ...         0      0     0       0       0         0   \n",
      "933         0  ...         0      0     0       0       0         0   \n",
      "934         0  ...         0      0     0       0       0         0   \n",
      "935         0  ...         0      0     0       0       0         0   \n",
      "936         0  ...         0      0     0       0       0         0   \n",
      "937         0  ...         0      0     0       0       0         0   \n",
      "938         0  ...         0      0     0       0       0         0   \n",
      "939         0  ...         0      0     0       0       0         0   \n",
      "940         0  ...         0      0     0       0       0         0   \n",
      "941         0  ...         0      0     0       0       0         0   \n",
      "942         0  ...         0      0     0       0       0         0   \n",
      "943         0  ...         0      0     0       0       0         0   \n",
      "944         0  ...         0      0     0       0       0         0   \n",
      "945         0  ...         0      0     0       0       0         0   \n",
      "946         0  ...         0      0     0       0       0         0   \n",
      "947         0  ...         0      0     0       0       0         0   \n",
      "948         0  ...         0      0     0       0       0         0   \n",
      "949         0  ...         0      0     0       0       0         0   \n",
      "950         0  ...         0      0     0       0       0         0   \n",
      "951         0  ...         0      0     0       0       0         0   \n",
      "952         0  ...         0      0     0       0       0         0   \n",
      "953         0  ...         0      0     0       0       0         0   \n",
      "954         0  ...         0      0     0       0       0         0   \n",
      "955         0  ...         0      0     0       0       0         0   \n",
      "956         0  ...         0      0     0       0       0         0   \n",
      "957         0  ...         0      0     0       0       0         0   \n",
      "958         0  ...         0      0     0       0       0         0   \n",
      "\n",
      "    interesting proof outshine sister  \n",
      "0             0     0        0      0  \n",
      "1             0     0        0      2  \n",
      "2             0     0        0      0  \n",
      "3             0     0        0      0  \n",
      "4             0     0        0      0  \n",
      "5             0     0        0      0  \n",
      "6             0     0        0      0  \n",
      "7             0     0        0      0  \n",
      "8             0     0        0      0  \n",
      "9             0     0        0      0  \n",
      "10            0     0        0      0  \n",
      "11            0     0        0      0  \n",
      "12            0     0        0      0  \n",
      "13            0     0        0      0  \n",
      "14            0     0        0      0  \n",
      "15            0     0        0      0  \n",
      "16            0     0        0      0  \n",
      "17            0     0        0      0  \n",
      "18            0     0        0      0  \n",
      "19            0     0        0      0  \n",
      "20            0     0        0      0  \n",
      "21            0     0        0      0  \n",
      "22            0     0        0      0  \n",
      "23            0     0        0      0  \n",
      "24            0     0        0      0  \n",
      "25            0     0        0      0  \n",
      "26            0     0        0      0  \n",
      "27            0     0        0      0  \n",
      "28            0     0        0      0  \n",
      "29            0     0        0      0  \n",
      "..          ...   ...      ...    ...  \n",
      "929           0     0        0      0  \n",
      "930           0     0        0      0  \n",
      "931           0     0        0      0  \n",
      "932           0     0        0      0  \n",
      "933           0     0        0      0  \n",
      "934           0     0        0      0  \n",
      "935           0     0        0      0  \n",
      "936           0     0        0      0  \n",
      "937           0     0        0      0  \n",
      "938           0     0        0      0  \n",
      "939           0     0        0      0  \n",
      "940           0     0        0      0  \n",
      "941           0     0        0      0  \n",
      "942           0     0        0      0  \n",
      "943           0     0        0      0  \n",
      "944           0     0        0      0  \n",
      "945           0     0        0      0  \n",
      "946           0     0        0      0  \n",
      "947           0     0        0      0  \n",
      "948           0     0        0      0  \n",
      "949           0     0        0      0  \n",
      "950           0     0        0      0  \n",
      "951           0     0        0      0  \n",
      "952           0     0        0      0  \n",
      "953           0     0        0      0  \n",
      "954           0     0        0      0  \n",
      "955           0     0        0      0  \n",
      "956           0     0        0      0  \n",
      "957           0     0        0      0  \n",
      "958           0     0        0      0  \n",
      "\n",
      "[959 rows x 3048 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (word_counts.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = word_counts.iloc[:,:-2]\n",
    "y = word_counts.iloc[:,:-2]\n",
    "\n",
    "y_pred = KMeans(n_clusters=2, random_state=42).fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1\n",
      " 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1\n",
      " 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1\n",
      " 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1\n",
      " 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1\n",
      " 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1\n",
      " 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster based on authors and are there certain authors using common words or not? bar graph? potentially try pca too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2cb9c02467d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclust_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclust_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclust_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-2cb9c02467d0>\u001b[0m in \u001b[0;36mdoKmeans\u001b[0;34m(X, nclust)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdoKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnclust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclust_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 311\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "def doKmeans(X, nclust=2):\n",
    "    model = KMeans(nclust)\n",
    "    model.fit(X)\n",
    "    clust_labels = model.predict(X)\n",
    "    cent = model.cluster_centers_\n",
    "    return (clust_labels, cent)\n",
    "\n",
    "clust_labels, cent = doKmeans(word_counts.iloc[:,:-2], 2)\n",
    "kmeans = pd.DataFrame(clust_labels)\n",
    "word_counts.insert((word_counts.shape[1]),'kmeans',kmeans)\n",
    "print(Kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means and mini batch k-means solutions:\n",
      "col_0    0    1\n",
      "row_0          \n",
      "0       70    0\n",
      "1      288  601\n"
     ]
    }
   ],
   "source": [
    "minibatchkmeans = MiniBatchKMeans(\n",
    "    init='random',\n",
    "    n_clusters=2,\n",
    "    batch_size=200)\n",
    "minibatchkmeans.fit(X)\n",
    "\n",
    "# Add the new predicted cluster memberships to the data frame.\n",
    "predict_mini = minibatchkmeans.predict(X)\n",
    "\n",
    "# Check the MiniBatch model against our earlier one.\n",
    "print('Comparing k-means and mini batch k-means solutions:')\n",
    "print(pd.crosstab(predict_mini, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9791304347826087\n",
      "\n",
      "Test set score: 0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 3048) (575,)\n",
      "Training set score: 0.9669565217391304\n",
      "\n",
      "Test set score: 0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') \n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
